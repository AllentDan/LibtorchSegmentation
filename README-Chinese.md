[English](https://github.com/AllentDan/SegmentationCpp) | ä¸­æ–‡

<div align="center">

![logo](https://raw.githubusercontent.com/AllentDan/ImageBase/main/OpenSource/LibtorchSegment.png)  
**åŸºäº[LibTorch](https://pytorch.org/)çš„C++å¼€æºå›¾åƒåˆ†å‰²ç¥ç»ç½‘ç»œåº“.**  

</div>
**â­å¦‚æœæœ‰ç”¨è¯·ç»™æˆ‘ä¸€ä¸ªstarâ­**

è¿™ä¸ªåº“å…·æœ‰ä»¥ä¸‹ä¼˜ç‚¹:

 - é«˜çº§çš„API (åªéœ€ä¸€è¡Œä»£ç å°±å¯åˆ›å»ºç½‘ç»œ)
 - 7 ç§æ¨¡å‹æ¶æ„å¯ç”¨äºå•ç±»æˆ–è€…å¤šç±»çš„åˆ†å‰²ä»»åŠ¡ (åŒ…æ‹¬Unet)
 - 7 ç§ç¼–ç å™¨ç½‘ç»œ
 - æ‰€æœ‰çš„ç¼–ç å™¨éƒ½æœ‰é¢„è®­ç»ƒæƒé‡ï¼Œå¯ä»¥æ›´å¿«æ›´å¥½åœ°æ”¶æ•›
 - ç›¸æ¯”äºpythonä¸‹çš„GPUå‰å‘æ¨ç†é€Ÿåº¦å…·æœ‰2å€æˆ–ä»¥ä¸Šçš„ä¼˜åŠ¿, cpuä¸‹ä¿æŒé€Ÿåº¦ä¸€è‡´. (Unetæµ‹è¯•äºGTX 2070S).
 
### [ğŸ“š Libtorchæ•™ç¨‹ ğŸ“š](https://github.com/AllentDan/LibtorchTutorials)

å¦‚æœä½ æƒ³å¯¹è¯¥å¼€æºé¡¹ç›®æœ‰æ›´å¤šæ›´è¯¦ç»†çš„äº†è§£ï¼Œè¯·å‰å¾€æœ¬äººå¦ä¸€ä¸ªå¼€æºé¡¹ç›®ï¼š[Libtorchæ•™ç¨‹](https://github.com/AllentDan/LibtorchTutorials) .

### ğŸ“‹ ç›®å½•
 1. [å¿«é€Ÿå¼€å§‹](#start)
 2. [ä¾‹å­](#examples)
 3. [è®­ç»ƒè‡ªå·±çš„æ•°æ®](#trainingOwn)
 4. [æ¨¡å‹](#models)
    1. [æ¶æ„](#architectures)
    2. [ç¼–ç å™¨](#encoders)
 5. [å®‰è£…](#installation)
 6. [æ„Ÿè°¢](#thanks)
 7. [å¼•ç”¨](#citing)
 8. [è¯ä¹¦](#license)

### â³ å¿«é€Ÿå¼€å§‹ <a name="start"></a>

#### 1. ç”¨ Libtorch Segment åˆ›å»ºä½ çš„ç¬¬ä¸€ä¸ªåˆ†å‰²ç½‘ç»œ

åˆ†å‰²æ¨¡å‹æ˜¯ LibTorch çš„ torch::nn::Moduleçš„æ´¾ç”Ÿç±», å¯ä»¥å¾ˆå®¹æ˜“ç”Ÿæˆ:

```cpp
#include "Segmentor.h"
auto model = UNet(1, /*num of classes*/
                  "resnet34", /*encoder name, could be resnet50 or others*/
                  "path to resnet34.pt"/*weight path pretrained on ImageNet, it is produced by torchscript*/
                  );
```
 - è§ [è¡¨](#architectures) æŸ¥çœ‹æ‰€æœ‰æ”¯æŒçš„æ¨¡å‹æ¶æ„
 - è§ [è¡¨](#encoders) æŸ¥çœ‹æ‰€æœ‰çš„ç¼–ç å™¨ç½‘ç»œå’Œç›¸åº”çš„é¢„è®­ç»ƒæƒé‡

#### 2. ç”Ÿæˆè‡ªå·±çš„é¢„è®­ç»ƒæƒé‡

æ‰€æœ‰ç¼–ç å™¨å‡å…·æœ‰é¢„è®­ç»ƒçš„æƒé‡ã€‚åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼Œä»¥ç›¸åŒçš„æ–¹å¼è®­ç»ƒæ•°æ®ï¼Œå¯èƒ½ä¼šè·å¾—æ›´å¥½çš„ç»“æœï¼ˆæ›´é«˜çš„æŒ‡æ ‡å¾—åˆ†å’Œæ›´å¿«çš„æ”¶æ•›é€Ÿåº¦ï¼‰ã€‚è¿˜å¯ä»¥åœ¨å†»ç»“ä¸»å¹²çš„åŒæ—¶ä»…è®­ç»ƒè§£ç å™¨å’Œåˆ†å‰²å¤´ã€‚

```python
import torch
from torchvision import models

# resnet50 for example
model = models.resnet50(pretrained=True)
model.eval()
var=torch.ones((1,3,224,224))
traced_script_module = torch.jit.trace(model, var)
traced_script_module.save("resnet50.pt")
```

æ­å–œä½ ï¼ å¤§åŠŸå‘Šæˆï¼ ç°åœ¨ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨è‡ªå·±å–œæ¬¢çš„ä¸»å¹²å’Œåˆ†å‰²æ¡†æ¶æ¥è®­ç»ƒæ¨¡å‹äº†ã€‚

### ğŸ’¡ ä¾‹å­ <a name="examples"></a>
 - ä½¿ç”¨æ¥è‡ªPASCAL VOCæ•°æ®é›†çš„å›¾åƒè¿›è¡Œäººä½“åˆ†å‰²æ•°æ®è®­ç»ƒæ¨¡å‹. "voc_person_seg" ç›®å½•åŒ…å«32ä¸ªjsonæ ‡ç­¾åŠå…¶ç›¸åº”çš„jpegå›¾åƒç”¨äºè®­ç»ƒï¼Œè¿˜æœ‰8ä¸ªjsonæ ‡ç­¾ä»¥åŠç›¸åº”çš„å›¾åƒç”¨äºéªŒè¯ã€‚
```cpp
Segmentor<FPN> segmentor;
segmentor.Initialize(0/*gpu id, -1 for cpu*/,
                    512/*resize width*/,
                    512/*resize height*/,
                    {"background","person"}/*class name dict, background included*/,
                    "resnet34"/*backbone name*/,
                    "your path to resnet34.pt");
segmentor.Train(0.0003/*initial leaning rate*/,
                300/*training epochs*/,
                4/*batch size*/,
                "your path to voc_person_seg",
                ".jpg"/*image type*/,
                "your path to save segmentor.pt");
```

- é¢„æµ‹æµ‹è¯•ã€‚é¡¹ç›®ä¸­æä¾›äº†ä»¥ResNet34ä¸ºéª¨å¹²ç½‘ç»œçš„FPNç½‘ç»œï¼Œè®­ç»ƒäº†ä¸€äº›å‘¨æœŸå¾—åˆ°segmentor.ptæ–‡ä»¶ã€‚ æ‚¨å¯ä»¥ç›´æ¥æµ‹è¯•åˆ†å‰²ç»“æœ:
```cpp
cv::Mat image = cv::imread("your path to voc_person_seg\\val\\2007_004000.jpg");
Segmentor<FPN> segmentor;
segmentor.Initialize(0,512,512,{"background","person"},
                      "resnet34","your path to resnet34.pt");
segmentor.LoadWeight("segmentor.pt"/*the saved .pt path*/);
segmentor.Predict(image,"person"/*class name for showing*/);
```
é¢„æµ‹ç»“æœæ˜¾ç¤ºå¦‚ä¸‹:

![](https://raw.githubusercontent.com/AllentDan/SegmentationCpp/main/prediction.jpg)

### ğŸ§‘â€ğŸš€ è®­ç»ƒè‡ªå·±çš„æ•°æ® <a name="trainingOwn"></a>
- åˆ›å»ºè‡ªå·±çš„æ•°æ®é›†. ä½¿ç”¨"pip install"å®‰è£…[labelme](https://github.com/wkentaro/labelme)å¹¶æ ‡æ³¨ä½ çš„å›¾åƒ. å°†è¾“å‡ºçš„jsonæ–‡ä»¶å’Œå›¾åƒåˆ†æˆä»¥ä¸‹æ–‡ä»¶å¤¹ï¼š
```
Dataset
â”œâ”€â”€ train
â”‚   â”œâ”€â”€ xxx.json
â”‚   â”œâ”€â”€ xxx.jpg
â”‚   â””......
â”œâ”€â”€ val
â”‚   â”œâ”€â”€ xxxx.json
â”‚   â”œâ”€â”€ xxxx.jpg
â”‚   â””......
```
- è®­ç»ƒæˆ–æµ‹è¯•ã€‚å°±åƒâ€œ voc_person_segâ€çš„ç¤ºä¾‹ä¸€æ ·ï¼Œç”¨è‡ªå·±çš„æ•°æ®é›†è·¯å¾„æ›¿æ¢â€œ voc_person_segâ€ã€‚


### ğŸ“¦ Models <a name="models"></a>

#### Architectures <a name="architectures"></a>
 - [x] Unet [[paper](https://arxiv.org/abs/1505.04597)]
 - [x] FPN [[paper](http://presentations.cocodataset.org/COCO17-Stuff-FAIR.pdf)]
 - [x] PAN [[paper](https://arxiv.org/abs/1805.10180)]
 - [x] PSPNet [[paper](https://arxiv.org/abs/1612.01105)]
 - [x] LinkNet [[paper](https://arxiv.org/abs/1707.03718)]
 - [x] DeepLabV3 [[paper](https://arxiv.org/abs/1706.05587)]
 - [x] DeepLabV3+ [[paper](https://arxiv.org/abs/1802.02611)]
 - [ ] UNet++ [[paper](https://arxiv.org/pdf/1807.10165.pdf)]

#### Encoders <a name="encoders"></a>
- [x] ResNet
- [x] ResNext
- [ ] ResNest
- [ ] Se-Net

ä»¥ä¸‹æ˜¯è¯¥é¡¹ç›®ä¸­å—æ”¯æŒçš„ç¼–ç å™¨çš„åˆ—è¡¨ã€‚é™¤resnestå¤–ï¼Œæ‰€æœ‰ç¼–ç å™¨æƒé‡éƒ½å¯ä»¥é€šè¿‡torchvisionç”Ÿæˆã€‚é€‰æ‹©é€‚å½“çš„ç¼–ç å™¨ï¼Œç„¶åå•å‡»ä»¥å±•å¼€è¡¨æ ¼ï¼Œç„¶åé€‰æ‹©ç‰¹å®šçš„ç¼–ç å™¨åŠå…¶é¢„è®­ç»ƒçš„æƒé‡ã€‚

<details>
<summary style="margin-left: 25px;">ResNet</summary>
<div style="margin-left: 25px;">

|Encoder                         |Weights                         |Params, M                       |
|--------------------------------|:------------------------------:|:------------------------------:|
|resnet18                        |imagenet                        |11M                             |
|resnet34                        |imagenet                        |21M                             |
|resnet50                        |imagenet                        |23M                             |
|resnet101                       |imagenet                        |42M                             |
|resnet152                       |imagenet                        |58M                             |

</div>
</details>

<details>
<summary style="margin-left: 25px;">ResNeXt</summary>
<div style="margin-left: 25px;">

|Encoder                         |Weights                         |Params, M                       |
|--------------------------------|:------------------------------:|:------------------------------:|
|resnext50_32x4d                 |imagenet                        |22M                             |
|resnext101_32x8d                |imagenet                        |86M                             |

</div>
</details>

<details>
<summary style="margin-left: 25px;">ResNeSt</summary>
<div style="margin-left: 25px;">

|Encoder                         |Weights                         |Params, M                       |
|--------------------------------|:------------------------------:|:------------------------------:|
|timm-resnest14d                 |imagenet                        |8M                              |
|timm-resnest26d                 |imagenet                        |15M                             |
|timm-resnest50d                 |imagenet                        |25M                             |
|timm-resnest101e                |imagenet                        |46M                             |
|timm-resnest200e                |imagenet                        |68M                             |
|timm-resnest269e                |imagenet                        |108M                            |
|timm-resnest50d_4s2x40d         |imagenet                        |28M                             |
|timm-resnest50d_1s4x24d         |imagenet                        |23M                             |

</div>
</details>

<details>
<summary style="margin-left: 25px;">SE-Net</summary>
<div style="margin-left: 25px;">

|Encoder                         |Weights                         |Params, M                       |
|--------------------------------|:------------------------------:|:------------------------------:|
|senet154                        |imagenet                        |113M                            |
|se_resnet50                     |imagenet                        |26M                             |
|se_resnet101                    |imagenet                        |47M                             |
|se_resnet152                    |imagenet                        |64M                             |
|se_resnext50_32x4d              |imagenet                        |25M                             |
|se_resnext101_32x4d             |imagenet                        |46M                             |

</div>
</details>

### ğŸ›  å®‰è£… <a name="installation"></a>
**ä¾èµ–åº“:**

- [Opencv 3+](https://opencv.org/releases/)
- [Libtorch 1.7+](https://pytorch.org/)

**Windows:**

é…ç½®libtorch å¼€å‘ç¯å¢ƒ. [Visual studio](https://allentdan.github.io/2020/12/16/pytorch%E9%83%A8%E7%BD%B2torchscript%E7%AF%87) å’Œ [Qt Creator](https://allentdan.github.io/2021/01/21/QT%20Creator%20+%20Opencv4.x%20+%20Libtorch1.7%E9%85%8D%E7%BD%AE/#more)å·²ç»é€šè¿‡libtorch1.7x releaseçš„éªŒè¯. 

**Linux && MacOS:**

æŒ‰ç…§å®˜æ–¹æä¾›çš„pytorch c++ [éƒ¨ç½²](https://pytorch.org/tutorials/advanced/cpp_export.html). æ¯”Windowsè¦ç®€å•è®¸å¤š.

### ğŸ¤ æ„Ÿè°¢ <a name="thanks"></a>
è¿™ä¸ªé¡¹ç›®è¿˜åœ¨æ–½å·¥ï¼Œä»¥ä¸‹æ˜¯ç›®å‰ç»™äºˆå¸®åŠ©çš„é¡¹ç›®.
- [official pytorch](https://github.com/pytorch/pytorch)
- [qubvel SMP](https://github.com/qubvel/segmentation_models.pytorch)
- [wkentaro labelme](https://github.com/wkentaro/labelme)
- [nlohmann json](https://github.com/nlohmann/json)

### ğŸ“ å¼•ç”¨
```
@misc{Chunyu:2021,
  Author = {Chunyu Dong},
  Title = {Libtorch Segment},
  Year = {2021},
  Publisher = {GitHub},
  Journal = {GitHub repository},
  Howpublished = {\url{https://github.com/AllentDan/SegmentationCpp}}
}
```

### ğŸ›¡ï¸ è¯ä¹¦ <a name="license"></a>
è¯¥é¡¹ç›®ä»¥ [MIT License](https://github.com/qubvel/segmentation_models.pytorch/blob/master/LICENSE)å¼€æºï¼Œåˆ«å¿˜äº†ç‚¹èµå“Ÿ
![stargazers over time](https://starchart.cc/AllentDan/SegmentationCpp.svg)
